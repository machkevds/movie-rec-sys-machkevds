{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9iz1BppeFp2rJSFFk4FGP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation System"
      ],
      "metadata": {
        "id": "cK8ummuSThWp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EfdV7DrqTfh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "lJQ-UCWHZMG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to auto reload any updated py files\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "UhwVjUl1ElEH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ILfQfphYfqFI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download dataset"
      ],
      "metadata": {
        "id": "dyketIU8ZSHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip -q ml-100k.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGJY-7L_Q-xc",
        "outputId": "f2038fe0-7fb0-40dd-c54a-fc37c77ad674"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-16 20:12:02--  https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  14.3MB/s    in 0.3s    \n",
            "\n",
            "2025-06-16 20:12:02 (14.3 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_loader.py\n",
        "\n",
        "# load ratings & movie data\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_ratings(path=\"ml-100k/u.data\"):\n",
        "  '''load file with user ratings'''\n",
        "  return pd.read_csv(path, sep='\\t', header=None,\n",
        "                     names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"])\n",
        "\n",
        "def load_movies(path='ml-100k/u.item'):\n",
        "  '''load file with movie metadata'''\n",
        "  return pd.read_csv(path, sep='|', encoding='latin-1', header=None,\n",
        "                     names=[\"movie_id\", \"title\", \"release_date\", \"video_release_date\",\n",
        "                            \"IMDb_URL\"] + [f\"genre_{i}\" for i in range(19)])\n",
        "\n",
        "def build_user_item_matrix(ratings_df):\n",
        "  ''' pivot to user-item matrix with NaNs for missing values'''\n",
        "  return ratings_df.pivot_table(index='user_id', columns='movie_id', values='rating')\n",
        "\n",
        "def fill_missing_zero(matrix):\n",
        "  '''filling NaNs with 0 for cosine similarity'''\n",
        "  return matrix.fillna(0)\n",
        "\n",
        "def center_ratings(matrix):\n",
        "  '''returning mean centered ratings matrix (for pearson similarity)'''\n",
        "  user_means = matrix.mean(axis=1)\n",
        "  return matrix.sub(user_means, axis=0), user_means\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHyT-jhVRvGR",
        "outputId": "df12a83d-b29d-428f-966c-de43d85b9326"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#usage reference\n",
        "from data_loader import load_ratings, load_movies, build_user_item_matrix, fill_missing_zero, center_ratings\n",
        "\n",
        "ratings = load_ratings()\n",
        "movies = load_movies()\n",
        "user_item = build_user_item_matrix(ratings)\n",
        "user_item_filled = fill_missing_zero(user_item)\n",
        "user_item_centered, user_means = center_ratings(user_item)"
      ],
      "metadata": {
        "id": "GIe_lpqWnESK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating similarity.py\n",
        "\n",
        "%%writefile similarity.py\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def compute_cosine_similarity(matrix):\n",
        "  ''' Computing the cosine similarity between users based on rating vectors.\n",
        "      The input is a matrix with users as rows, movies as columns and no NaNs (filled with zeroes)'''\n",
        "\n",
        "  similarity = cosine_similarity(matrix.values)\n",
        "  return pd.DataFrame(similarity, index=matrix.index, columns=matrix.index)\n",
        "\n",
        "def compute_pearson_similarity(centered_matrix):\n",
        "    '''Computes the Pearson correlation between users on mean centered data..\n",
        "       The input is a matrix with mean-centered ratings (NaNs allowed)'''\n",
        "    return centered_matrix.T.corr(method='pearson')\n",
        "\n",
        "\n",
        "def get_top_k_neighbors(similarity_matrix, user_id, k=5):\n",
        "  ''' Get top k most similar users to a given user, excluding themselves.'''\n",
        "  user_similarities = similarity_matrix.loc[user_id]\n",
        "  top_k = user_similarities.drop(index=user_id).nlargest(k)\n",
        "  return top_k\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZfy4HIULaFZ",
        "outputId": "78099900-51c3-47c8-f5f8-8a6c8ac4bf1f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing similarity.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# usage reference\n",
        "\n",
        "from similarity import compute_cosine_similarity, compute_pearson_similarity, get_top_k_neighbors\n",
        "\n",
        "# user cosine similarity\n",
        "user_similarity_cosine = compute_cosine_similarity(user_item_filled)\n",
        "\n",
        "# user pearson similarity\n",
        "user_similarity_pearson = compute_pearson_similarity(user_item_centered)\n",
        "\n",
        "# using pearson to get similar users to a certain other user\n",
        "top_users = get_top_k_neighbors(user_similarity_pearson, user_id=1, k=5)"
      ],
      "metadata": {
        "id": "AGf4jpwlnH1Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating predictor.py\n",
        "%%writefile predictor.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def predict_rating_cosine(user_id, movie_id, rating_matrix, similarity_matrix):\n",
        "  ''' preduct a user's rating for a movie'''\n",
        "  if movie_id not in rating_matrix.columns:\n",
        "    return np.nan\n",
        "\n",
        "  movie_ratings = rating_matrix[movie_id]\n",
        "  rated_users = movie_ratings[movie_ratings > 0].index\n",
        "\n",
        "  if user_id not in similarity_matrix.index:\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "  similarities = similarity_matrix.loc[user_id, rated_users]\n",
        "  ratings = movie_ratings[rated_users]\n",
        "\n",
        "  numerator = np.dot(similarities, ratings)\n",
        "  denominator = np.sum(np.abs(similarities))\n",
        "\n",
        "  return numerator / denominator if denominator != 0 else np.nan\n",
        "\n",
        "\n",
        "def predict_rating_pearson(user_id, movie_id, centered_matrix, similarity_matrix, user_means):\n",
        "  ''' predict user's rating fora  movie using pearson & centered matrix'''\n",
        "  if movie_id not in centered_matrix.columns or user_id not in similarity_matrix.index:\n",
        "    return np.nan\n",
        "\n",
        "  movie_ratings = centered_matrix[movie_id]\n",
        "  rated_users = movie_ratings[movie_ratings.notna()].index\n",
        "  similarities = similarity_matrix.loc[user_id, rated_users]\n",
        "  ratings = centered_matrix.loc[rated_users, movie_id]\n",
        "\n",
        "  #filter out NaNs\n",
        "  valid_mask = ratings.notna() & similarities.notna()\n",
        "  similarities = similarities[valid_mask]\n",
        "  ratings = ratings[valid_mask]\n",
        "\n",
        "  #check denominator\n",
        "  denominator = np.sum(np.abs(similarities))\n",
        "  if len(similarities) ==0 or denominator == 0:\n",
        "    return np.nan\n",
        "\n",
        "  numerator = np.dot(similarities, ratings)\n",
        "  return user_means.loc[user_id] + (numerator / denominator)\n",
        "\n",
        "\n",
        "# addig top k neighbor filtering\n",
        "def get_top_k_similar_users(user_id, similarity_matrix, k=10, min_similarity=0.0):\n",
        "  ''' returning the top k most similar users to the target user'''\n",
        "  if user_id not in similarity_matrix.index:\n",
        "    return []\n",
        "\n",
        "  similarities = similarity_matrix.loc[user_id].drop(user_id)\n",
        "  similarities = similarities[similarities >= min_similarity]\n",
        "  top_k = similarities.sort_values(ascending=False).head(k)\n",
        "  return top_k.index\n",
        "\n",
        "#predict rating top k cosine\n",
        "def predict_rating_top_k_cosine(user_id, movie_id, rating_matrix, similarity_matrix, k=10, min_similarity=0.0):\n",
        "  ''' predict rating using cosine similarity and top-k neighbors'''\n",
        "  if movie_id not in rating_matrix.columns or user_id not in similarity_matrix.index:\n",
        "    return np.nan\n",
        "\n",
        "  movie_ratings = rating_matrix[movie_id]\n",
        "  rated_users = movie_ratings[movie_ratings > 0].index\n",
        "\n",
        "  # finding overlap between rated users and top k similar ones\n",
        "  top_k_users = get_top_k_similar_users(user_id, similarity_matrix, k, min_similarity)\n",
        "  neighbors = [u for u in top_k_users if u in rated_users]\n",
        "\n",
        "  if not neighbors:\n",
        "    return np.nan\n",
        "\n",
        "  similarities = similarity_matrix.loc[user_id, neighbors]\n",
        "  ratings = rating_matrix.loc[neighbors, movie_id]\n",
        "\n",
        "  numerator = np.dot(similarities, ratings)\n",
        "  denominator = np.sum(np.abs(similarities))\n",
        "\n",
        "  return numerator / denominator if denominator != 0 else np.nan\n",
        "\n",
        "\n",
        "#predict rating top k pearson\n",
        "def predict_rating_top_k_pearson(user_id, movie_id, centered_matrix, similarity_matrix, user_means, k=10, min_similarity=0.0):\n",
        "  '''predict using pearson & top k neighbors'''\n",
        "  if movie_id not in centered_matrix.columns or user_id not in similarity_matrix.index:\n",
        "    return np.nan\n",
        "\n",
        "  movie_ratings = centered_matrix[movie_id]\n",
        "  rated_users = movie_ratings[movie_ratings.notna()].index\n",
        "\n",
        "  top_k_users = get_top_k_similar_users(user_id, similarity_matrix, k, min_similarity)\n",
        "  neighbors = [u for u in top_k_users if u in rated_users]\n",
        "\n",
        "  if not neighbors:\n",
        "    return np.nan\n",
        "\n",
        "  similarities = similarity_matrix.loc[user_id, neighbors]\n",
        "  ratings = centered_matrix.loc[neighbors, movie_id]\n",
        "\n",
        "  valid_mask = ratings.notna() & similarities.notna()\n",
        "  similarities = similarities[valid_mask]\n",
        "  ratings = ratings[valid_mask]\n",
        "\n",
        "  denominator = np.sum(np.abs(similarities))\n",
        "  if len(similarities) == 0 or denominator == 0:\n",
        "    return np.nan\n",
        "\n",
        "  numerator = np.dot(similarities,ratings)\n",
        "  return user_means.loc[user_id] + (numerator / denominator)\n",
        "\n",
        "\n",
        "# predict rating item-item CF cosine\n",
        "def predict_rating_item_cosine(user_id, movie_id, rating_matrix, item_similarity_matrix):\n",
        "  '''predict rating for a user/movie using item-item cos similarity'''\n",
        "  if user_id not in rating_matrix.index or movie_id not in item_similarity_matrix.index:\n",
        "    return np.nan\n",
        "\n",
        "  user_ratings = rating_matrix.loc[user_id]\n",
        "  rated_items = user_ratings[user_ratings > 0].index\n",
        "\n",
        "  similarities = item_similarity_matrix.loc[movie_id, rated_items]\n",
        "  ratings = user_ratings[rated_items]\n",
        "\n",
        "  numerator = np.dot(similarities, ratings)\n",
        "  denominator = np.sum(np.abs(similarities))\n",
        "\n",
        "  return numerator / denominator if denominator != 0 else np.nan\n",
        "\n",
        "# predict rating item CF Pearson\n",
        "def predict_rating_pearson(user_id, movie_id, centered_matrix, item_similarity_matrix, item_means):\n",
        "  '''predict rating using item-item pearson sim & centered ratings'''\n",
        "  if user_id not in centered_matrix.index or movie_id not in item_similarity_matrix.index:\n",
        "    return np.nan\n",
        "\n",
        "  user_ratings = centered_matrix.loc[user_id]\n",
        "  rated_items = user_ratings[user_ratings.notna()].index\n",
        "\n",
        "  similarities = item_similarity_matrix.loc[movie_id, rated_items]\n",
        "  ratings = centered_matrix.loc[user_id, rated_items]\n",
        "\n",
        "  valid_mask = ratings.notna() & similarities.notna()\n",
        "  similarities = similarities[valid_mask]\n",
        "  ratings = ratings[valid_mask]\n",
        "\n",
        "  denominator = np.sum(np.abs(similarities))\n",
        "  if len(similarities) == 0 or denominator == 0:\n",
        "    return np.nan\n",
        "\n",
        "  numerator = np.dot(similarities, ratings)\n",
        "  return item_means.loc[movie_id] + (numerator / denominator)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HeOKcp5bfuPK",
        "outputId": "efb67471-3849-474b-ca48-cc2134a710d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing predictor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# update predictor with top k\n",
        "from predictor import predict_rating_top_k_cosine, predict_rating_top_k_pearson\n",
        "\n",
        "\n",
        "topk_cosine_pred = predict_rating_top_k_cosine(\n",
        "    user_id=1,\n",
        "    movie_id=50,\n",
        "    rating_matrix= user_item_filled,\n",
        "    similarity_matrix= user_similarity_cosine,\n",
        "    k=30\n",
        ")\n",
        "\n",
        "topk_pearson_pred = predict_rating_top_k_pearson(\n",
        "    user_id=1,\n",
        "    movie_id=50,\n",
        "    centered_matrix= user_item_centered,\n",
        "    similarity_matrix= user_similarity_pearson,\n",
        "    user_means=user_means,\n",
        "    k=30\n",
        ")\n",
        "\n",
        "print(f\"top k Cosine Prediction: {topk_cosine_pred: .2f}\")\n",
        "print(f\"top kPearson prediction: {topk_pearson_pred:.2f}\")\n"
      ],
      "metadata": {
        "id": "aoKLHbeimLjx",
        "outputId": "f5707c99-3735-4d24-fa65-4b7aaf705228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top k Cosine Prediction:  4.74\n",
            "top kPearson prediction: 4.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after implementing top k predictions:\n",
        "# the results now show a refined memory based collaborative filtering\n",
        "# by using only the top-k most similar users(instead of using all of them)\n",
        "# making prediction less noisy and more realistic than the previous one\n",
        "\n",
        "# get top k similar users - selects k most sim. users to targer user(using cos or pears)\n",
        "# with similarity threshold\n",
        "\n",
        "# predict_rating_top_k - uses solely those top-k users when predicting a rating, avoiding. weak/noisy similarities.\n",
        "\n",
        "\n",
        "#full cosine similarity - 4.40\n",
        "#full pearson similarity - 4.48\n",
        "# including all users even noisy/unrelated ones\n",
        "\n",
        "#top k cosine (k=30) - 4.74| recommendation is more confident\n",
        "#top k pearson (k=30) - 4.10| rec is more conservative\n",
        "\n",
        "#metrics. such as Precision@K and Recall@K\n",
        "# precision@ k - from K recommended movies, how many were actually liked?\n",
        "# recall@ k - of all movies that the user liked, how many did we recommend in top K?\n",
        "\n",
        "#other model based CF approaches for ranking instead of rating prediction\n",
        "\n",
        "# BPR bayesian personalized ranking - pairwise learning to rank\n",
        "#for a given user u, if they liked item i,\n",
        "#they should prefer i over some item j they didn’t interact with.\n",
        "#Maximize probability that i ≻ j.\n",
        "#is better for clicks, views (lightFM, Implicit)\n",
        "\n",
        "#ALS Alternating least squares\n",
        "# matrix factorization method\n",
        "# supports explicit & implicit feedback (Spark MLlib. implicit, surprise)\n",
        "\n",
        "#NN Based neural recommenders\n",
        "#learn complex non linear interactions between user/items\n",
        "# NeuMF, NCF, AutoRec, DeepFM\n",
        "# use of transformers for sequence based rec\n"
      ],
      "metadata": {
        "id": "QV3uj3FziQvo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding top N recommendation generation\n",
        "\n",
        "%%writefile topn.py\n",
        "\n",
        "def recommend_top_n(user_id, rating_matrix, similarity_matrix, n=10, k=30, min_similarity=0.0):\n",
        "  '''recommend top N items based on top K similar users'''\n",
        "  if user_id not in similarity_matrix.index:\n",
        "    return []\n",
        "\n",
        "  # getting top k similar users\n",
        "  sim_scores = similarity_matrix.loc[user_id].drop(user_id)\n",
        "  top_k_users = sim_scores[sim_scores >= min_similarity].nlargest(k).index\n",
        "\n",
        "  #items that the targer user has already rated\n",
        "  user_rated_items = set(rating_matrix.loc[user_id][rating_matrix.loc[user_id] > 0].index)\n",
        "\n",
        "  #items rated by top k users but not by the target user\n",
        "  candidate_items = set()\n",
        "  for neighbor in top_k_users:\n",
        "    neighbor_rated = rating_matrix.loc[neighbor][rating_matrix.loc[neighbor] > 0 ].index\n",
        "    candidate_items.update(neighbor_rated)\n",
        "\n",
        "  candidate_items.difference_update(user_rated_items)\n",
        "\n",
        "  #predict ratings for candidate items\n",
        "  predictions = {}\n",
        "  for item in candidate_items:\n",
        "    numer, denom = 0.0, 0.0\n",
        "    for neighbor in top_k_users:\n",
        "      sim = similarity_matrix.at[user_id, neighbor]\n",
        "      neighbor_rating = rating_matrix.at[neighbor, item] if item in rating_matrix.columns else 0\n",
        "\n",
        "      if neighbor_rating >0:\n",
        "        numer += sim* neighbor_rating\n",
        "        denom += abs(sim)\n",
        "\n",
        "    if denom>0:\n",
        "      predictions[item] = numer / denom\n",
        "\n",
        "\n",
        "  # return top N highest predicted ratings\n",
        "  top_n_items = sorted(predictions.items(), key=lambda x: x[1], reverse= True)[:n]\n",
        "  return top_n_items"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3PR4nCaoKCP",
        "outputId": "86a0f547-925a-448c-87ee-a8354ca7e594"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing topn.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# usage reference for topn\n",
        "\n",
        "from topn import recommend_top_n\n",
        "\n",
        "#generate top 5 recommended movie_ids for user 1 using cos similarity\n",
        "top_5cosine = recommend_top_n(\n",
        "    user_id=1,\n",
        "    rating_matrix=user_item_filled,\n",
        "    similarity_matrix = user_similarity_cosine,\n",
        "    n=5,\n",
        "    k=30,\n",
        "    min_similarity=0.1\n",
        ")\n",
        "\n",
        "print(\"top 5 Cosine recommended\")\n",
        "print(top_5cosine)\n",
        "\n",
        "\n",
        "#.generate top 5 rec movie_ids for user 1 using pears similarity\n",
        "top_5pearson = recommend_top_n(\n",
        "    user_id=1,\n",
        "    rating_matrix=user_item_filled,\n",
        "    similarity_matrix=user_similarity_pearson,\n",
        "    n=5,\n",
        "    k=30,\n",
        "    min_similarity=0.1\n",
        ")\n",
        "\n",
        "print(\"top 5 Pearson\")\n",
        "print(top_5pearson)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pDjp4uSrwR7",
        "outputId": "7de2a49f-6b59-47b4-f412-799a19e73ba2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top 5 Cosine recommended\n",
            "[(690, np.float64(5.000000000000001)), (522, np.float64(5.0)), (641, np.float64(5.0)), (853, np.float64(5.0)), (1111, np.float64(5.0))]\n",
            "top 5 Pearson\n",
            "[(524, np.float64(5.0)), (1048, np.float64(5.0)), (603, np.float64(5.0)), (604, np.float64(5.0)), (650, np.float64(5.0))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# showing movie titles from top_5cosine\n",
        "top_movie_ids = [movie_id for movie_id, _ in top_5cosine]\n",
        "recommended_titles = movies[movies['movie_id'].isin(top_movie_ids)][['movie_id', 'title']]\n",
        "\n",
        "print(\"Top. 5 Cosine N recommendation for user 1\")\n",
        "print(recommended_titles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIPobVENE8o0",
        "outputId": "7dab523d-c6a3-4e09-ba26-5e95b61a68ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top. 5 Cosine N recommendation for user 1\n",
            "      movie_id                        title\n",
            "521        522           Down by Law (1986)\n",
            "640        641        Paths of Glory (1957)\n",
            "689        690  Seven Years in Tibet (1997)\n",
            "852        853             Braindead (1992)\n",
            "1110      1111      Double Happiness (1994)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# movie titles form top_5pearson\n",
        "top_movie_ids = [movie_id for movie_id, _ in top_5pearson]\n",
        "recommended_titles = movies[movies['movie_id'].isin(top_movie_ids)][['movie_id', 'title']]\n",
        "\n",
        "\n",
        "print(\"Top. 5 Pearson N recommendation for user 1\")\n",
        "print(recommended_titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRjEBWJWFZV1",
        "outputId": "ff9cee16-2cb9-4f96-a2ea-a117314d715d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top. 5 Pearson N recommendation for user 1\n",
            "      movie_id                                            title\n",
            "523        524                       Great Dictator, The (1940)\n",
            "602        603                               Rear Window (1954)\n",
            "603        604                     It Happened One Night (1934)\n",
            "649        650  Seventh Seal, The (Sjunde inseglet, Det) (1957)\n",
            "1047      1048                             She's the One (1996)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gTiVTDFTLSFx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top k filtering ensures only top 5 similar users are considered\n",
        "# top n recommendations are about ranking items (not just predicting ratings)\n",
        "\n",
        "#cos sim is angle based. | movies popular among similar-rating users\n",
        "#pear sim is mean centered / correlation based | movies w similar rating patterns, not just high ratings\n",
        "\n",
        "#eg cos sim| 690 and 641 may have had similar fan bases to the user\n",
        "#eg pear sim| 603 and 604 are critically acclaimed classics"
      ],
      "metadata": {
        "id": "I8rDgXJiLBFP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating evaluator.py\n",
        "\n",
        "# with extra functions for ranking evaluation\n",
        "\n",
        "%%writefile evaluator.py\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from collections import defaultdict\n",
        "\n",
        "def train_test_split(ratings_df, test_size=0.2, seed=42):\n",
        "    \"\"\"\n",
        "    splitting ratings into train/test sets (randomly)\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    shuffled = ratings_df.sample(frac=1, random_state=seed)\n",
        "    test_count = int(len(shuffled) * test_size)\n",
        "\n",
        "\n",
        "    test_df = shuffled.iloc[:test_count]\n",
        "    train_df = shuffled.iloc[test_count:]\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "def evaluate(predict_fn, test_df, *predict_args):\n",
        "  ''' eval prediction function on test set '''\n",
        "\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  for row in test_df.itertuples():\n",
        "    pred = predict_fn(row.user_id, row.movie_id, *predict_args)\n",
        "    if not np.isnan(pred):\n",
        "      y_true.append(row.rating)\n",
        "      y_pred.append(pred)\n",
        "\n",
        "  rmse= np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "  mae = mean_absolute_error(y_true, y_pred)\n",
        "  return rmse, mae\n",
        "\n",
        "\n",
        "def get_top_n_recommendations(test_df, rating_matrix, similarity_matrix, recommend_fn, n=5, k=20, min_similarity=0.0):\n",
        "  ''' for each user in test_df, get top n recs.'''\n",
        "  user_recs = defaultdict(list)\n",
        "  users = test_df['user_id'].unique()\n",
        "\n",
        "  for user_id in users:\n",
        "    recs = recommend_fn(\n",
        "        user_id = user_id,\n",
        "        rating_matrix = rating_matrix,\n",
        "        similarity_matrix = similarity_matrix,\n",
        "        n=n,\n",
        "        k=k,\n",
        "        min_similarity = min_similarity\n",
        "    )\n",
        "    if recs:\n",
        "      recommended_items = [item for item, _ in recs]\n",
        "      user_recs[user_id] = recommended_items\n",
        "  return user_recs\n",
        "\n",
        "def precision_recall_at_k(user_recs, test_df, k=5):\n",
        "  '''computes precision@k & recall@k w/ ground truth from test_df'''\n",
        "  relevant = defaultdict(set)\n",
        "  for row in test_df.itertuples():\n",
        "    if row.rating >= 4:\n",
        "      relevant[row.user_id].add(row.movie_id)\n",
        "\n",
        "  precisions, recalls = [], []\n",
        "\n",
        "  for user_id, recommended_items in user_recs.items():\n",
        "    true_items = relevant.get(user_id, set())\n",
        "    if not true_items:\n",
        "      continue\n",
        "\n",
        "    recommended_top_k = set(recommended_items[:k])\n",
        "    n_rel_and_rec = len(recommended_top_k & true_items)\n",
        "\n",
        "    precision = n_rel_and_rec / k\n",
        "    recall = n_rel_and_rec / len(true_items)\n",
        "\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "\n",
        "  avg_precision = np.mean(precisions)\n",
        "  avg_recall =np.mean(recalls)\n",
        "  return avg_precision, avg_recall"
      ],
      "metadata": {
        "id": "jGL6FmAqZL5F",
        "outputId": "2976ec33-d1b4-45e0-c88b-6188cbcd0d3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# usage reference\n",
        "from data_loader import build_user_item_matrix, fill_missing_zero, center_ratings\n",
        "from similarity import compute_cosine_similarity, compute_pearson_similarity\n",
        "from predictor import predict_rating_cosine, predict_rating_pearson\n",
        "from evaluator import train_test_split, evaluate"
      ],
      "metadata": {
        "id": "iNin3j21bJy2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the original ratings\n",
        "train_df, test_df = train_test_split(ratings)\n",
        "\n",
        "# build matrices from training data only\n",
        "train_user_item = build_user_item_matrix(train_df)\n",
        "\n",
        "train_user_item_filled = fill_missing_zero(train_user_item)\n",
        "\n",
        "train_user_item_centered, train_user_means = center_ratings(train_user_item)\n",
        "\n",
        "# get similarities from training data\n",
        "user_sim_cosine = compute_cosine_similarity(train_user_item_filled)\n",
        "\n",
        "user_sim_pearson = compute_pearson_similarity(train_user_item_centered)\n"
      ],
      "metadata": {
        "id": "uGC_KxdhbfvJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate cosine\n",
        "\n",
        "rmse_cos, mae_cos = evaluate(\n",
        "    predict_rating_top_k_cosine,\n",
        "    test_df,\n",
        "    train_user_item_filled,\n",
        "    user_sim_cosine\n",
        ")\n",
        "\n",
        "print(f\"Cosine Top K RMSE: {rmse_cos:4f}, Cosine Top K MAE: {mae_cos:4f}\")\n"
      ],
      "metadata": {
        "id": "QZvUSDqHcTwJ",
        "outputId": "61d79f9e-2f30-4a2b-e6a7-7d29cf9c043f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Top K RMSE: 1.107655, Cosine Top K MAE: 0.860426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate pearson\n",
        "\n",
        "rmse_pear, mae_pear = evaluate(\n",
        "    predict_rating_top_k_pearson,\n",
        "    test_df,\n",
        "    train_user_item_centered,\n",
        "    user_sim_pearson,\n",
        "    train_user_means\n",
        ")\n",
        "\n",
        "print(f\"Pearson Top K RMSE: {rmse_pear:4f}, Pearson Top K MAE:{mae_pear:4f}\")"
      ],
      "metadata": {
        "id": "rjlNUjFHcrvP",
        "outputId": "59508083-7436-40cb-86c8-ba1adcbb8775",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson Top K RMSE: 1.277526, Pearson Top K MAE:1.001483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate but now with top-N ranking evaluation\n",
        "from evaluator import get_top_n_recommendations, precision_recall_at_k\n",
        "\n",
        "top_n_recs = get_top_n_recommendations(\n",
        "    test_df = test_df,\n",
        "    rating_matrix = train_user_item_filled,\n",
        "    similarity_matrix = user_sim_cosine,\n",
        "    recommend_fn = recommend_top_n, #from topn.py\n",
        "    n=5,\n",
        "    k=30,\n",
        "    min_similarity = 0.2\n",
        ")\n",
        "\n",
        "prcsn_5, rcll_5 = precision_recall_at_k(top_n_recs,  test_df, k=5)\n",
        "print(f\"Precision@5 : {prcsn_5:.4f},  Recall@5 : {rcll_5:.4f}\")\n"
      ],
      "metadata": {
        "id": "aVHLvK8nGztM",
        "outputId": "634167a2-a729-4fad-ff18-310409e10c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@5 : 0.0054,  Recall@5 : 0.0040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Review of results\n",
        "\n",
        "# Precision@5 : 0.0054,\n",
        "# meaning ~3 out of 5 recommended movies were already rated highly by the user, based on existing test data\n",
        "\n",
        "# Recall@5 : 0.0040\n",
        "# meaning only %40 of liked movies were retrieved in the top 5 predictions, the rest were not.\n",
        "\n",
        "\n",
        "# SUMMARY\n",
        "# precision@k - % of recommneded movies that are actually relevant, measures how many in top k are known to be relevatn based on existing ratings\n",
        "# recall@k - % of relevant movies that were actually recommended, measures how many of the relevant(liked) movies were found in the top-k\n",
        "# \"relevant\" here - user gave a high rating, usually 4>=\n",
        "# .@k - number of novies recommended, .@5 = we are evaluating the top 5 predicted movies\n"
      ],
      "metadata": {
        "id": "tJNK86ULvrjl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############## OVERALL SUMMARY OF PROJECT ###############\n",
        "\n",
        "# Collaborative Filtering:\n",
        "# User behavior based, not based in attributes of items/products\n",
        "# eg. If users A & B liked the same things in the past, they might like similar things in future\n",
        "\n",
        "#=========================================\n",
        "# MEMORY BASED CF / DONE HERE\n",
        "\n",
        "# user-based CF -> Cosine Similarity -> Predict a rating based on similar users' ratings (angle betweem vectors)\n",
        "# user-based CF -> Pearson Similarity -> Adjust for user biases by centering ratings (linear relationship between variables)\n",
        "# Top K Filtering -> Cosine / Pearson (Top K) -> Only use the top K similar users to avoid noise\n",
        "# RMSE / MAE - For accuracy of predicted ratings\n",
        "# Precision@K and Recall@K - Accuracy of recommendation lists (used in top N recommendation evaluation)\n",
        "\n",
        "\n",
        "# Not Done here yet:\n",
        "# Item-Based CF - Use similar movies instead of similar users\n",
        "# Significance Weighting - Weight down similarities with fewer co-rated items.\n",
        "#=================================================\n",
        "\n",
        "\n",
        "\n",
        "# Up ahead...\n",
        "#==========================================\n",
        "# MODEL BASED CF:\n",
        "# Learn latent factors via optimization (matrix factorization), big systems like netflix use\n",
        "\n",
        "# Most common types of ModeL Based CF\n",
        "# SVD / Matrix Factorization -> Learns user/item vectors that explain ratings\n",
        "# Alternating Least Squares (ALS) -> Optimization-based matrix factorization (used at scale)\n",
        "# Deep Learning (Autoencoders) -> Learns Patterns in sparse rating data\n",
        "# Neural Collaborative Filtering -> Uses embeddings & neural nets for scoring\n",
        "\n",
        "#==========================================\n",
        "\n",
        "\n",
        "# Further ahead... REAL LIFE USAGES\n",
        "#================================================\n",
        "# Big companies use:\n",
        "# NDCG@K (Normalized Discounted Cumulative Gain) -> Rewards correct ranking in top-N\n",
        "# MAP@K (Mean Average Precision) -> Measures how early relevant items appear\n",
        "# Hit Rate@K -> Measure whther any relevant item appears in top-K\n",
        "# Coverage -> % of items recommended at least once\n",
        "# Diversity / Novelty / Serendipity - > Encourage unexpected but relevant recs\n",
        "# Business KPIs -> Watch time, click-through, purchase rate, etc.\n",
        "\n",
        "# These ALL often optimize MULTIPLE OBJECTIVES at once, not just prediction error.\n",
        "#==================================================\n"
      ],
      "metadata": {
        "id": "Zq5T4Xcv2ISu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Item Based Collaborative Filtering (ITEM-ITEM CF)\n",
        "\n",
        "%%writefile item_similarity.py\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def compute_item_similarity_cosine(user_item_matrix):\n",
        "  ''' cosine similarity between items (columns)'''\n",
        "  item_vectors = user_item_matrix.T # transposes columns as rows\n",
        "  similarity = cosine_similarity(item_vectors)\n",
        "  return pd.DataFrame(similarity, index=item_vectors.index, columns=item_vectors.index)\n",
        "\n",
        "def compute_item_similarity_pearson(user_item_centered):\n",
        "  '''pearson corelation between items'''\n",
        "  return user_item_centered.corr(method='pearson')\n",
        ""
      ],
      "metadata": {
        "id": "NFviuuajVMCY",
        "outputId": "e7a8f66f-462d-4507-d3b3-77bb635cf818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing item_similarity.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# usage reference for item_similarity.py\n",
        "#now comparing columns (items) instead of rows (users)\n",
        "\n",
        "from item_similarity import compute_item_similarity_cosine, compute_item_similarity_pearson\n",
        "\n",
        "#get similarity matrices\n",
        "item_similarity_cosine = compute_item_similarity_cosine(user_item_filled)\n",
        "item_similarity_pearson = compute_item_similarity_pearson(user_item_centered)\n",
        "\n",
        "# example\n",
        "item_similarity_cosine.loc[50].sort_values(ascending=False).head(10)\n",
        "item_similarity_pearson.loc[50].sort_values(ascending=False).head(10)\n"
      ],
      "metadata": {
        "id": "o-0s4H7xWPz-",
        "outputId": "256132bb-8dc6-4edc-c784-1e38b1054971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "movie_id\n",
              "788     1.0\n",
              "1242    1.0\n",
              "784     1.0\n",
              "50      1.0\n",
              "1542    1.0\n",
              "1497    1.0\n",
              "1189    1.0\n",
              "766     1.0\n",
              "1523    1.0\n",
              "1549    1.0\n",
              "Name: 50, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>50</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movie_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1242</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1542</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1189</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1523</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1549</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}