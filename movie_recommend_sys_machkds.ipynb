{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTnCqIPqjAXGIejdDFY05w"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation System"
      ],
      "metadata": {
        "id": "cK8ummuSThWp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EfdV7DrqTfh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "lJQ-UCWHZMG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to auto reload any updated py files\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "UhwVjUl1ElEH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ILfQfphYfqFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download dataset"
      ],
      "metadata": {
        "id": "dyketIU8ZSHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip -q ml-100k.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGJY-7L_Q-xc",
        "outputId": "ec3ac223-fda0-4704-eec8-e616048bcfe7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-09 16:27:18--  https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  5.15MB/s    in 0.9s    \n",
            "\n",
            "2025-06-09 16:27:20 (5.15 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_loader.py\n",
        "\n",
        "# load ratings & movie data\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_ratings(path=\"ml-100k/u.data\"):\n",
        "  '''load file with user ratings'''\n",
        "  return pd.read_csv(path, sep='\\t', header=None,\n",
        "                     names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"])\n",
        "\n",
        "def load_movies(path='ml-100k/u.item'):\n",
        "  '''load file with movie metadata'''\n",
        "  return pd.read_csv(path, sep='|', encoding='latin-1', header=None,\n",
        "                     names=[\"movie_id\", \"title\", \"release_date\", \"video_release_date\",\n",
        "                            \"IMDb_URL\"] + [f\"genre_{i}\" for i in range(19)])\n",
        "\n",
        "def build_user_item_matrix(ratings_df):\n",
        "  ''' pivot to user-item matrix with NaNs for missing values'''\n",
        "  return ratings_df.pivot_table(index='user_id', columns='movie_id', values='rating')\n",
        "\n",
        "def fill_missing_zero(matrix):\n",
        "  '''filling NaNs with 0 for cosine similarity'''\n",
        "  return matrix.fillna(0)\n",
        "\n",
        "def center_ratings(matrix):\n",
        "  '''returning mean centered ratings matrix (for pearson similarity)'''\n",
        "  user_means = matrix.mean(axis=1)\n",
        "  return matrix.sub(user_means, axis=0), user_means\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHyT-jhVRvGR",
        "outputId": "7a5db4b3-bfa6-4d87-e334-e69cdf948407"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#usage reference\n",
        "from data_loader import load_ratings, load_movies, build_user_item_matrix, fill_missing_zero, center_ratings\n",
        "\n",
        "ratings = load_ratings()\n",
        "movies = load_movies()\n",
        "user_item = build_user_item_matrix(ratings)\n",
        "user_item_filled = fill_missing_zero(user_item)\n",
        "user_item_centered, user_means = center_ratings(user_item)"
      ],
      "metadata": {
        "id": "GIe_lpqWnESK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating similarity.py\n",
        "\n",
        "%%writefile similarity.py\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def compute_cosine_similarity(matrix):\n",
        "  ''' Computing the cosine similarity between users based on rating vectors.\n",
        "      The input is a matrix with users as rows, movies as columns and no NaNs (filled with zeroes)'''\n",
        "\n",
        "  similarity = cosine_similarity(matrix.values)\n",
        "  return pd.DataFrame(similarity, index=matrix.index, columns=matrix.index)\n",
        "\n",
        "def compute_pearson_similarity(centered_matrix):\n",
        "    '''Computes the Pearson correlation between users on mean centered data..\n",
        "       The input is a matrix with mean-centered ratings (NaNs allowed)'''\n",
        "    return centered_matrix.T.corr(method='pearson')\n",
        "\n",
        "\n",
        "def get_top_k_neighbors(similarity_matrix, user_id, k=5):\n",
        "  ''' Get top k most similar users to a given user, excluding themselves.'''\n",
        "  user_similarities = similarity_matrix.loc[user_id]\n",
        "  top_k = user_similarities.drop(index=user_id).nlargest(k)\n",
        "  return top_k\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZfy4HIULaFZ",
        "outputId": "0d9a3c5b-b198-4d4e-cce6-093601ae2c35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing similarity.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# usage reference\n",
        "\n",
        "from similarity import compute_cosine_similarity, compute_pearson_similarity, get_top_k_neighbors\n",
        "\n",
        "# user cosine similarity\n",
        "user_similarity_cosine = compute_cosine_similarity(user_item_filled)\n",
        "\n",
        "# user pearson similarity\n",
        "user_similarity_pearson = compute_pearson_similarity(user_item_centered)\n",
        "\n",
        "# using pearson to get similar users to a certain other user\n",
        "top_users = get_top_k_neighbors(user_similarity_pearson, user_id=1, k=5)"
      ],
      "metadata": {
        "id": "AGf4jpwlnH1Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating predictor.py\n",
        "%%writefile predictor.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def predict_rating_cosine(user_id, movie_id, rating_matrix, similarity_matrix):\n",
        "  ''' preduct a user's rating for a movie'''\n",
        "  if movie_id not in rating_matrix.columns:\n",
        "    return np.nan\n",
        "\n",
        "  movie_ratings = rating_matrix[movie_id]\n",
        "  rated_users = movie_ratings[movie_ratings > 0].index\n",
        "\n",
        "  if user_id not in similarity_matrix.index:\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "  similarities = similarity_matrix.loc[user_id, rated_users]\n",
        "  ratings = movie_ratings[rated_users]\n",
        "\n",
        "  numerator = np.dot(similarities, ratings)\n",
        "  denominator = np.sum(np.abs(similarities))\n",
        "\n",
        "  return numerator / denominator if denominator != 0 else np.nan\n",
        "\n",
        "\n",
        "def predict_rating_pearson(user_id, movie_id, centered_matrix, similarity_matrix, user_means):\n",
        "  ''' predict user's rating fora  movie using pearson & centered matrix'''\n",
        "  if movie_id not in centered_matrix.columns or user_id not in similarity_matrix.index:\n",
        "    return np.nan\n",
        "\n",
        "  movie_ratings = centered_matrix[movie_id]\n",
        "  rated_users = movie_ratings[movie_ratings.notna()].index\n",
        "  similarities = similarity_matrix.loc[user_id, rated_users]\n",
        "  ratings = centered_matrix.loc[rated_users, movie_id]\n",
        "\n",
        "  #filter out NaNs\n",
        "  valid_mask = ratings.notna() & similarities.notna()\n",
        "  similarities = similarities[valid_mask]\n",
        "  ratings = ratings[valid_mask]\n",
        "\n",
        "  #check denominator\n",
        "  denominator = np.sum(np.abs(similarities))\n",
        "  if len(similarities) ==0 or denominator == 0:\n",
        "    return np.nan\n",
        "\n",
        "  numerator = np.dot(similarities, ratings)\n",
        "  return user_means.loc[user_id] + (numerator / denominator)\n",
        "\n",
        "\n",
        "# addig top k neighbor filtering\n",
        "def get_top_k_similar_users(user_id, similarity_matrix, k=10, min_similarity=0.0):\n",
        "  ''' returning the top k most similar users to the target user'''\n",
        "  if user_id not in similarity_matrix.index:\n",
        "    return []\n",
        "\n",
        "  similarities = similarity_matrix.loc[user_id].drop(user_id)\n",
        "  similarities = similarities[similarities >= min_similarity]\n",
        "  top_k = similarities.sort_values(ascending=False).head(k)\n",
        "  return top_k.index\n",
        "\n",
        "#predict rating top k cosine\n",
        "def predict_rating_top_k_cosine(user_id, movie_id, rating_matrix, similarity_matrix, k=10, min_similarity=0.0):\n",
        "  ''' predict rating using cosine similarity and top-k neighbors'''\n",
        "  if movie_id not in rating_matrix.columns or user_id not in similarity_matrix.index:\n",
        "    return np.nan\n",
        "\n",
        "  movie_ratings = rating_matrix[movie_id]\n",
        "  rated_users = movie_ratings[movie_ratings > 0].index\n",
        "\n",
        "  # finding overlap between rated users and top k similar ones\n",
        "  top_k_users = get_top_k_similar_users(user_id, similarity_matrix, k, min_similarity)\n",
        "  neighbors = [u for u in top_k_users if u in rated_users]\n",
        "\n",
        "  if not neighbors:\n",
        "    return np.nan\n",
        "\n",
        "  similarities = similarity_matrix.loc[user_id, neighbors]\n",
        "  ratings = rating_matrix.loc[neighbors, movie_id]\n",
        "\n",
        "  numerator = np.dot(similarities, ratings)\n",
        "  denominator = np.sum(np.abs(similarities))\n",
        "\n",
        "  return numerator / denominator if denominator != 0 else np.nan\n",
        "\n",
        "\n",
        "#predict rating top k pearson\n",
        "def predict_rating_top_k_pearson(user_id, movie_id, centered_matrix, similarity_matrix, user_means, k=10, min_similarity=0.0):\n",
        "  '''predict using pearson & top k neighbors'''\n",
        "  if movie_id not in centered_matrix.columns or user_id not in similarity_matrix.index:\n",
        "    return np.nan\n",
        "\n",
        "  movie_ratings = centered_matrix[movie_id]\n",
        "  rated_users = movie_ratings[movie_ratings.notna()].index\n",
        "\n",
        "  top_k_users = get_top_k_similar_users(user_id, similarity_matrix, k, min_similarity)\n",
        "  neighbors = [u for u in top_k_users if u in rated_users]\n",
        "\n",
        "  if not neighbors:\n",
        "    return np.nan\n",
        "\n",
        "  similarities = similarity_matrix.loc[user_id, neighbors]\n",
        "  ratings = centered_matrix.loc[neighbors, movie_id]\n",
        "\n",
        "  valid_mask = ratings.notna() & similarities.notna()\n",
        "  similarities = similarities[valid_mask]\n",
        "  ratings = ratings[valid_mask]\n",
        "\n",
        "  denominator = np.sum(np.abs(similarities))\n",
        "  if len(similarities) == 0 or denominator == 0:\n",
        "    return np.nan\n",
        "\n",
        "  numerator = np.dot(similarities,ratings)\n",
        "  return user_means.loc[user_id] + (numerator / denominator)\n",
        "\n"
      ],
      "metadata": {
        "id": "HeOKcp5bfuPK",
        "outputId": "18ee3aaa-ae3d-49e0-9d58-283be453267b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting predictor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# update predictor with top k\n",
        "from predictor import predict_rating_top_k_cosine, predict_rating_top_k_pearson\n",
        "\n",
        "\n",
        "topk_cosine_pred = predict_rating_top_k_cosine(\n",
        "    user_id=1,\n",
        "    movie_id=50,\n",
        "    rating_matrix= user_item_filled,\n",
        "    similarity_matrix= user_similarity_cosine,\n",
        "    k=30\n",
        ")\n",
        "\n",
        "topk_pearson_pred = predict_rating_top_k_pearson(\n",
        "    user_id=1,\n",
        "    movie_id=50,\n",
        "    centered_matrix= user_item_centered,\n",
        "    similarity_matrix= user_similarity_pearson,\n",
        "    user_means=user_means,\n",
        "    k=30\n",
        ")\n",
        "\n",
        "print(f\"top k Cosine Prediction: {topk_cosine_pred: .2f}\")\n",
        "print(f\"top kPearson prediction: {topk_pearson_pred:.2f}\")\n"
      ],
      "metadata": {
        "id": "aoKLHbeimLjx",
        "outputId": "e4942386-2148-4914-e9d0-2f03777058ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top k Cosine Prediction:  4.74\n",
            "top kPearson prediction: 4.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after implementing top k predictions:\n",
        "# the results now show a refined memory based collaborative filtering\n",
        "# by using only the top-k most similar users(instead of using all of them)\n",
        "# making prediction less noisy and more realistic than the previous one\n",
        "\n",
        "# get top k similar users - selects k most sim. users to targer user(using cos or pears)\n",
        "# with similarity threshold\n",
        "\n",
        "# predict_rating_top_k - uses solely those top-k users when predicting a rating, avoiding. weak/noisy similarities.\n",
        "\n",
        "\n",
        "#full cosine similarity - 4.40\n",
        "#full pearson similarity - 4.48\n",
        "# including all users even noisy/unrelated ones\n",
        "\n",
        "#top k cosine (k=30) - 4.74| recommendation is more confident\n",
        "#top k pearson (k=30) - 4.10| rec is more conservative\n",
        "\n",
        "#metrics. such as Precision@K and Recall@K\n",
        "# precision@ k - from K recommended movies, how many were actually liked?\n",
        "# recall@ k - of all movies that the user liked, how many did we recommend in top K?\n",
        "\n",
        "#other model based CF approaches for ranking instead of rating prediction\n",
        "\n",
        "# BPR bayesian personalized ranking - pairwise learning to rank\n",
        "#for a given user u, if they liked item i,\n",
        "#they should prefer i over some item j they didn’t interact with.\n",
        "#Maximize probability that i ≻ j.\n",
        "#is better for clicks, views (lightFM, Implicit)\n",
        "\n",
        "#ALS Alternating least squares\n",
        "# matrix factorization method\n",
        "# supports explicit & implicit feedback (Spark MLlib. implicit, surprise)\n",
        "\n",
        "#NN Based neural recommenders\n",
        "#"
      ],
      "metadata": {
        "id": "QV3uj3FziQvo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating evaluator.py\n",
        "%%writefile evaluator.py\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "def train_test_split(ratings_df, test_size=0.2, seed=42):\n",
        "    \"\"\"\n",
        "    splitting ratings into train/test sets (randomly)\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    shuffled = ratings_df.sample(frac=1, random_state=seed)\n",
        "    test_count = int(len(shuffled) * test_size)\n",
        "\n",
        "\n",
        "    test_df = shuffled.iloc[:test_count]\n",
        "    train_df = shuffled.iloc[test_count:]\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "def evaluate(predict_fn, test_df, *predict_args):\n",
        "  ''' eval prediction function on test set '''\n",
        "\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  for row in test_df.itertuples():\n",
        "    pred = predict_fn(row.user_id, row.movie_id, *predict_args)\n",
        "    if not np.isnan(pred):\n",
        "      y_true.append(row.rating)\n",
        "      y_pred.append(pred)\n",
        "\n",
        "  rmse= np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "  mae = mean_absolute_error(y_true, y_pred)\n",
        "  return rmse, mae\n"
      ],
      "metadata": {
        "id": "jGL6FmAqZL5F",
        "outputId": "3befc929-9366-4932-dee8-ff2a58b50bea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# usage reference\n",
        "from data_loader import build_user_item_matrix, fill_missing_zero, center_ratings\n",
        "from similarity import compute_cosine_similarity, compute_pearson_similarity\n",
        "from predictor import predict_rating_cosine, predict_rating_pearson\n",
        "from evaluator import train_test_split, evaluate"
      ],
      "metadata": {
        "id": "iNin3j21bJy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the original ratings\n",
        "train_df, test_df = train_test_split(ratings)\n",
        "\n",
        "# build matrices from training data only\n",
        "train_user_item = build_user_item_matrix(train_df)\n",
        "\n",
        "train_user_item_filled = fill_missing_zero(train_user_item)\n",
        "\n",
        "train_user_item_centered, train_user_means = center_ratings(train_user_item)\n",
        "\n",
        "# get similarities from training data\n",
        "user_sim_cosine = compute_cosine_similarity(train_user_item_filled)\n",
        "\n",
        "user_sim_pearson = compute_pearson_similarity(train_user_item_centered)\n"
      ],
      "metadata": {
        "id": "uGC_KxdhbfvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate cosine\n",
        "\n",
        "rmse_cos, mae_cos = evaluate(\n",
        "    predict_rating_cosine,\n",
        "    test_df,\n",
        "    train_user_item_filled,\n",
        "    user_sim_cosine\n",
        ")\n",
        "\n",
        "print(f\"Cosine RMSE: {rmse_cos:4f}, Cosine MAE: {mae_cos:4f}\")\n"
      ],
      "metadata": {
        "id": "QZvUSDqHcTwJ",
        "outputId": "fc75c4b8-c2aa-4779-ff23-a606c778d707",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine RMSE: 1.014553, Cosine MAE: 0.806039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate pearson\n",
        "\n",
        "rmse_pear, mae_pear = evaluate(\n",
        "    predict_rating_pearson,\n",
        "    test_df,\n",
        "    train_user_item_centered,\n",
        "    user_sim_pearson,\n",
        "    train_user_means\n",
        ")\n",
        "\n",
        "print(f\"Pearson RMSE: {rmse_pear:4f}, Pearson MAE:{mae_pear:4f}\")"
      ],
      "metadata": {
        "id": "rjlNUjFHcrvP",
        "outputId": "b325b867-5554-49f8-c1ce-fca22cade246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson RMSE: 0.947520, Pearson MAE:0.747008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aVHLvK8nGztM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}